{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"이번글은 Oracle Insert 시 발생하는 데드락 문제 분석과 해결 방안에 대해 작성해보았습니다. 데드락이 발생한 상황 가정 상품(Product)과 사은품(Gift) 두 개의 테이블이 있다고 가정해 보겠습니다. \n여기서 상품 테이블의 기본 키(PK)는 사은품 테이블의 기본 키(PK)이자 외래 키(FK)로 설정되어 있으며, 상품 테이블의 PK는 시퀀스(…","fields":{"slug":"/deadlock/"},"frontmatter":{"date":"November 10, 2024","title":"Deadlock in Oracle with Insert query","tags":["Oracle","Deadlock"]},"rawMarkdownBody":"이번글은 Oracle Insert 시 발생하는 데드락 문제 분석과 해결 방안에 대해 작성해보았습니다.\n\n# 데드락이 발생한 상황 가정\n상품(Product)과 사은품(Gift) 두 개의 테이블이 있다고 가정해 보겠습니다. <br>\n여기서 상품 테이블의 기본 키(PK)는 사은품 테이블의 기본 키(PK)이자 외래 키(FK)로 설정되어 있으며, 상품 테이블의 PK는 시퀀스(sequence)를 통해 생성됩니다. <br>\n상품 및 사은품 Insert 쿼리는 다음과 같은 흐름으로 이루어집니다.\n\n아래 흐름은 하나의 트랜잭션에서 동작합니다.\n1) 상품 sequence의 LAST NUMBER로 return id를 지정\n2) 상품 insert. PK는 sequence의 NEXT_VAL로 지정한다.\n3) 1)에서 return_id를 가져와 사은품의 PK로 지정하여 insert.\n\n# 문제 발견\n위와 같은 흐름에서는 데이터의 일관성 문제는 있을 수 있지만, 데드락이 발생하지는 않습니다.<br>\n데드락은 두 개의 트랜잭션이 서로가 보유한 자원을 기다리며 발생하는 상황을 의미합니다.<br>\n위 상황에서 데드락이 발생하지 않는 이유에 대해 알아보겠습니다.<br>\n트랜잭션 1에서 return id를 x, 트랜잭션 2에서 return id를 y라고 가정해보겠습니다.<br>\n트랜잭션 1에서 상품 insert시 실제 저장되는 PK는 x+A, 트랜잭션 2에서 상품 insert시 실제 저장되는 PK는 y+B입니다. (x>0, y>0, A>=0, B>=0)\n<br>\n\n트랜잭션 1은 상품 pk가 x+A인 상품을 insert하여 x+A row X lock을 가지고 있고, \n트랜잭션 2은 상품 pk가 y+B인 상품을 insert하여 y+B row X lock을 지닌 상태에서 데드락이 발생할 수 있는 상황은 다음과 같습니다.<br>\n트랜잭션 1에서 사은품 insert시 pk가 x일 경우 참조성 확인을 위해 트랜잭션2의 상품의 pk인 y+B row를 READ, 트랜잭션 2에서 사은품 insert시 pk가 y일 경우 참조성 확인을 위해 트랜잭션1의 상품의 pk인 x+A row READ하는 경우입니다. <br>\n하지만 x = y+B 이며 y = x+A 수식이 성립할 수 없습니다.<br>\n<br>\n\n따라서, 상품 한개가 아닌 여러개를 저장하고 3단계에서 return id를 for문을 돌려 사은품의 PK를 (return_id+idx)로 저장하는 상황에서는 데드락이 발생합니다.\n\n\n# 문제 해결\n데드락을 방지하려면, 상품 테이블에 저장된 ID 목록을 한 번에 가져와 사은품 테이블에 Insert하는 방법을 사용해야 합니다. <br>\n하나의 세션에서만 동작하거나 낮은 동시성에서는 문제가 발생하지 않지만, 여러 세션이 동시에 상품을 Insert하게 되면 데드락 발생 가능성이 커집니다.\n\n\n# 결론\n이번 분석을 통해 Oracle에서도 Insert 과정에서 특정 조건 하에 데드락이 발생할 수 있음을 알게 되었으며, Sequence를 기반으로 PK가 생성되고 여러 종속적 Insert 작업이 있을 경우 데드락 위험이 존재합니다. <br>\n이러한 문제를 인지하고, 관련 레코드를 일괄 Insert하는 방식으로 해결할 수 있습니다."},{"excerpt":"웹 애플리케이션에서 데이터베이스와 연결을 맺을 때마다 Conenction을 생성한다면 많은 비용이 들뿐만 아니라, \nConnection 관리를 직접해줘야 되는 단점이 존재한다. 이를 해결하기 위해 Connection Pool을 사용하는데, 여러 오픈 소스 라이브러리가 존재한다.(Apache Commons DBCP, Tomcat-JDBC, HikariCP)…","fields":{"slug":"/ConnectionPool/"},"frontmatter":{"date":"August 11, 2024","title":"Connection Pool","tags":["Database"]},"rawMarkdownBody":"\n웹 애플리케이션에서 데이터베이스와 연결을 맺을 때마다 Conenction을 생성한다면 많은 비용이 들뿐만 아니라, \nConnection 관리를 직접해줘야 되는 단점이 존재한다.\n\n이를 해결하기 위해 Connection Pool을 사용하는데, 여러 오픈 소스 라이브러리가 존재한다.(Apache Commons DBCP, Tomcat-JDBC, HikariCP) \n\n또한, Connection Pool을 적절히 사용하기 위해선 구조와 원리에 대해 알고 있어야 한다.<br>\n사내에서 Apache Commons DBCP사용하므로 이에 대해 알아보자.\n\n## Commons DBCP 속성 설정\n- initialSize : 최초 시점에 getConnection() 를 통해 커넥션 풀에 채워 넣을 커넥션 개수 (default = 0)\n- maxTotal (1.x에서는 maxActive): 동시에 사용할 수 있는 최대 커넥션 개수 (default = 8)\n- maxIdle : Connection Pool에 반납할 때 최대로 유지될 수 있는 커넥션 개수 (default = 8)\n- minIdle : 최소한으로 유지할 커넥션 개수 (default = 0)\n- maxWaitMillis (1.x에서는 maxWait) : pool이 고갈되었을 경우 최대 대기 시간 (ms단위, default = -1 = 무한정)이걸 설정하지 않았는데, pool이 고갈되었고, 엔드유저의 요청은 계속 들어온다면?<br>\ntomcat 스레드 풀이 고갈되어 죽는다. 엔드유저 요청마다 무한정 대기중일 테니...<br>\n대부분 Connection의 개수 및 대기 상태일 때 설정값이 대부분이다. <br>\nConnection Pool 구조에 대해 더 알아보자\n\n## Connection 구조\n먼저 Connection Pool 구조는 아래와 같다.\n\n![Connection Pool 구조](connection_pool_archi.png)\nCommons DBCP는 PoolableConnection 타입의 커넥션을 생성하고 생성한 커넥션에 ConnectionEventListener를 등록한다. <br>\nConnectionEventListener에는 애플리케이션이 사용한 커넥션을 풀로 반환하기 위해 JDBC 드라이버가 호출할 수 있는 콜백 메서드가 있다. <br>\n이렇게 생성된 커넥션은 commons-pool의 addObject() 메서드로 커넥션 풀에 추가된다. <br>\n이때 commons-pool은 내부적으로 현재 시간을 담고 있는 타임스탬프와 추가된 커넥션의 레퍼런스를 한 쌍으로 하는 ObjectTimestampPair라는 자료구조를 생성한다. <br>\n그리고 이들을 LIFO(last in first out) 형태의 CursorableLinkedList로 관리한다.\n\n만약 8개의 커넥션을 최대로 활용할 수 있을 때, 4개는 사용 중이고 4개는 대기 중인 상태라면 커넥션 풀의 상태는 아래와 같다.\n\n![Connection Pool 상태](connection_pool_state.png)\n\n\n개수와 관련해서 몇 가지 조건이 존재한다.<br>\n- maxActive >= initialSize\nmaxActive = 10이고 initialSize = 20이라고 가정하면 최초에 커넥션을 생성할 때 initialSize 값이 최대 커넥션 개수인 maxActive 값보다 커서 논리적으로 오류가 있는 설정이다.\n- maxIdle >= minIdle\nmaxIdle < minIdle로 설정할 수는 있지만 최솟값이 최댓값보다 커서 논리적으로 오류가 있는 설정이다.\n- maxActive = maxIdle\nmaxActive 값과 maxIdle 값이 같은 것이 바람직하다. maxActive = 10이고 maxIdle = 5라고 가정해 보자. \n항상 커넥션을 동시에 5개는 사용하고 있는 상황에서 1개의 커넥션이 추가로 요청된다면 maxActive = 10이므로 1개의 추가 커넥션을 데이터베이스에 연결한 후 풀은 비즈니스 로직으로 커넥션을 전달한다. \n이후 비즈니스 로직이 커넥션을 사용 후 풀에 반납할 경우, maxIdle=5에 영향을 받아 커넥션을 실제로 닫아버리므로, 일부 커넥션을 매번 생성했다 닫는 비용이 발생할 수 있다.\n\nmaxActive 값은 DBMS의 설정과 애플리케이션 서버의 개수, Apache, Tomcat에서 동시에 처리할 수 있는 사용자 수 등을 고려해서 설정해야 한다\n\n## 유효성 검사 쿼리 설정\nJDBC 커넥션의 유효성은 validationQuery 옵션에 설정된 쿼리를 실행해 확인할 수 있다.  <br>\n- testOnBorrow: 커넥션 풀에서 커넥션을 얻어올 때 테스트 실행(기본값: true)<br>\n- testOnReturn: 커넥션 풀로 커넥션을 반환할 때 테스트 실행(기본값: false)<br>\n- testWhileIdle: Evictor 스레드가 실행될 때 (timeBetweenEvictionRunMillis > 0) 커넥션 풀 안에 있는 유휴 상태의 커넥션을 대상으로 테스트 실행(기본값: false)<br>\n\nvalidateQuery 옵션에는 아래와 같이 DB별로 Validation Query로 실제 테이블에 있는 데이터를 조회하지 않도록 설정해야 한다.\n\n- Oracle: select 1 from dual\n- Microsoft SQL Server: select 1\n- MySQL: select 1\n- CUBRID: select 1 from db_root\n\n## statement pooling 관련 옵션\npoolPreparedStatements 옵션을 true로 설정해서 Commons DBCP를 커넥션 풀뿐만 아니라 statement pool로도 사용할 수 있다. <br>\n이때는 반드시 maxOpenPreparedStatements 옵션을 같이 사용해 커넥션당 풀링할 PreparedStatement의 적절한 개수를 설정해야 한다.  <br>\n그렇지 않으면 런타임에서 메모리 부족(out of memory) 오류 등이 발생할 수 있다. <br>\n\nmaxOpenPreparedStatements 값은 문제가 발생지 않도록 50 정도로 작게 설정한 후 데이터베이스 관리자의 도움을 얻어 PreparedStatement의 캐시 적중률(hit ratio)을 관찰한 후 조정하기를 권장한다.  <br>\n여기서 설정한 PreparedStatement 개수는 개별 커넥션마다 할당된다.  <br>\n즉 커넥션 풀에 10개의 커넥션이 있을 때 maxOpenPreparedStatements = 50이라면 총 10 x 50 = 500개의 PreparedStatement가 캐시에 저장된다.  <br>\n절대 BasicDataSource 클래스에 설정되는 개수가 아니다. <br>\n\n### 출처\n[Commons DBCP 이해하기](https://d2.naver.com/helloworld/5102792)"},{"excerpt":"데이터베이스 모니터링 아키텍처를 설계 중 여러 데이터베이스의 Collector, Loader를 사용하기 위해 추상 팩토리 패턴, 전략패턴을 활용하여\n아키텍처를 설계해보았습니다. 추상 팩토리 패턴 객체 생성 패턴 중 하나로, 관련된 객체들을 하나의 팩토리(Factory)에서 생성하도록 하는 디자인 패턴입니다.객체 생성에 대한 구체적인 클래스를 감추고, 상위…","fields":{"slug":"/AbstractFactoryPatternStrategyPattern/"},"frontmatter":{"date":"August 04, 2024","title":"추상 팩토리 패턴과 전략패턴 활용","tags":["Design Pattern"]},"rawMarkdownBody":"데이터베이스 모니터링 아키텍처를 설계 중 여러 데이터베이스의 Collector, Loader를 사용하기 위해 추상 팩토리 패턴, 전략패턴을 활용하여\n아키텍처를 설계해보았습니다.\n## 추상 팩토리 패턴\n객체 생성 패턴 중 하나로, 관련된 객체들을 하나의 팩토리(Factory)에서 생성하도록 하는 디자인 패턴입니다.객체 생성에 대한 구체적인 클래스를 감추고, 상위 인터페이스만을 통해 객체를 생성함으로써 코드의 유연성과 확장성을 높이는 데 도움이 됩니다.\n### 추상 팩토리\n``` java\npublic interface MonitoringFactory {\n  Collector createCollector();\n  Loader createLoader();\n}\n\npublic class OracleMonitoringFactory implements MonitoringFactory {\n  @Override\n  public Collector createCollector() {\n    return new OracleCollector();\n  }\n\n  @Override\n  public Loader createLoader() {\n    return new OracleLoader();\n  }\n}\n\npublic class MysqlMonitoringFactory implements MonitoringFactory {\n  @Override\n  public Collector createCollector() {\n    return new MysqlCollector();\n  }\n\n  @Override\n  public Loader createLoader() {\n    return new MysqlLoader();\n  }\n}\n\npublic interface Collector<T> {\n  List<T> collect();\n}\n\npublic interface Loader<T> {\n  void load(List<T> entities);\n}\n```\n## 전략패턴\n전략패턴이란 객체의 행위를 클래스로 캡슐화하여 행위를 바꾸는 패턴입니다.\n특정 작업을 수행하는 방법이 여러 가지일 때, 유용합니다.\n``` java\npublic abstract class MonitoringStrategy {\n  private MonitoringFactory monitoringFactory;\n\n  void monitoring() {\n    Collector collector = monitoringFactory.createCollector();\n    Loader loader = monitoringFactory.createLoader();\n    List<T> entities = collector.collect();\n    loader.load(entities);\n  }\n\n  public MonitoringStrategy(MonitoringFactory monitoringFactory) {\n    this.monitoringFactory = monitoringFactory;\n  }\n}\n\npublic class OracleMonitoringStrategy extends MonitoringStrategy {\n  private MonitoringFactory monitoringFactory;\n\n  public OracleMonitoringStrategy(MonitoringFactory monitoringFactory) {\n    super(monitoringFactory);\n  }\n}\n\npublic class MysqlMonitoringStrategy extends MonitoringStrategy {\n  private MonitoringFactory monitoringFactory;\n\n  public MysqlMonitoringStrategy(MonitoringFactory monitoringFactory) {\n    super(monitoringFactory);\n  }\n}\n\npublic class DatabaseVendorMonitoringStrategy {\n  private HashMap<DatabaseVedor, MonitoringStrategy> databaseVendorMonitoringStrategy = new HashMap();\n  \n  static {\n    databaseVendorMonitoringStrategy.put(DatabaseVendor.Oracle, new OracleMonitoringStrategy());\n    databaseVendorMonitoringStrategy.put(DatabaseVendor.Mysql, new MysqlMonitoringStrategy());\n  }\n  \n  public void monitoring(DatabaseVendor databaseVendor) {\n    MonitoringStrategy monitoringStrategy = getMonitoringStrategyBy(databaseVendor);\n    monitoringStrategy.monitoring();\n  }\n\n  private getMonitoringStrategyBy(DatabaseVendor databaseVendor) {\n    if(!databaseVendorMonitoringStrategy.containsKey(databaseVendor)) {\n      throw new RuntimeException(databaseVendor + \"is not supported\");\n    }\n    return databaseVendorMonitoringStrategy.get(databaseVendor);\n  }\n}\n```\n\n"},{"excerpt":"AWS에서 인스턴스에 EBS를 여러 개 연결하면 Mount 시 EBS의 파일 크기가 작은 순으로 할당되는 것을 막기 위해, blkid 명령어로 EBS의 UUID를 얻어 Mount 시 EBS 연결을 UUID를 통해 할당되게 만들 수 있습니다. /etc/fstab 파일에 마운트할 디스크나 블록 디바이스의 파일 시스템 명( /dev/sda1 등)을 적는 것보다…","fields":{"slug":"/blkid/"},"frontmatter":{"date":"July 28, 2024","title":"blkid를 활용하여 Mount시 Volume 고정하기","tags":["Linux"]},"rawMarkdownBody":"AWS에서 인스턴스에 EBS를 여러 개 연결하면 Mount 시 EBS의 파일 크기가 작은 순으로 할당되는 것을 막기 위해, blkid 명령어로 EBS의 UUID를 얻어 Mount 시 EBS 연결을 UUID를 통해 할당되게 만들 수 있습니다.\n\n/etc/fstab 파일에 마운트할 디스크나 블록 디바이스의 파일 시스템 명( /dev/sda1 등)을 적는 것보다 UUID를 적는 것이 더 유리합니다.\n\n# blkid란?\nblkid는 디스크 블록 장치의 파일 시스템 종류와 함께 파일 시스템의 UUID 값을 출력합니다. 이 UUID 값은 이후 파일 시스템을 시스템에 자동 마운트하는 과정에서 사용됩니다.\n\n## 파일 시스템 생성\n아래 명령어를 사용하기 위해서는 파일 시스템을 디스크 블록에 먼저 생성해야 합니다.\n\n```shell\nmkfs.xfs -f /dev/sda1\n```\n## /etc/fstab 파일에 UUID 추가하기\n예를 들어, /dev/sdc1을 /mnt/my에 마운트하려면 /etc/fstab 파일에 다음과 같이 UUID를 추가합니다.\n\n```shell\nUUID=b1c7c897-be87-4487-9e81-bc6d2d146a0e /mnt/my ext4 defaults 0 2\n```\nUUID=b1c7c897-be87-4487-9e81-bc6d2d146a0e: 마운트할 디스크의 UUID.\n\n/mnt/my: 마운트할 디렉토리.\n\next4: 파일 시스템 타입.\n\ndefaults: 마운트 옵션. 여기서는 기본 옵션을 사용.\n\n0: 덤프(dump) 유틸리티로 파일 시스템을 백업할지를 결정. 0은 백업하지 않음을 의미.\n\n2: 부팅 시 파일 시스템 검사의 순서. 0은 파일 시스템 검사를 하지 않음을 의미하며, 1은 루트 파일 시스템을 검사, 2는 루트 파일 시스템 외의 파일 시스템을 검사합니다."},{"excerpt":"JNI(Java Native Interface)는 자바와 Native Code(C,C++)를 연결하는 데 사용되는 프레임워크이다.\nJNI를 통해 자바 Application에서 Natice Library를 호출하거나, Native Application에서 Java Method를 호출 할 수 있다. 이를 통해, 성능 향상, 기존 Native Library 재…","fields":{"slug":"/JNI/"},"frontmatter":{"date":"July 21, 2024","title":"JNI 사용하기","tags":["Java","JNI"]},"rawMarkdownBody":"JNI(Java Native Interface)는 자바와 Native Code(C,C++)를 연결하는 데 사용되는 프레임워크이다.\nJNI를 통해 자바 Application에서 Natice Library를 호출하거나, Native Application에서 Java Method를 호출 할 수 있다.\n\n이를 통해, 성능 향상, 기존 Native Library 재사용을 할 수 있다.\n\n## 자바에서 사용하는 방법\n\n### Native method\n\n자바는 Method 구현이 native code에서 제공될 것임을 나타내는데 사용되는 native keyword를 제공한다.\n\n공유 라이브러리 : Java 코드 내에서 라이브러리에 대한 참조만 있다. 실행 파일을 실행하는 환경이 프로그램에서 사용하는 libs의 모든 파일에 액세스 할 수 있어야 한다. \n\n공유 라이브러리는 클래스의 일부가 아닌 .so .ddl .dylib 파일 내에 Native Code를 별도로 보관한다.\n\n### 필요 구성요소\n\nJava Code\n\n- Native Keyword : Native로 표시된 모든 method는 native 공유 라이브러리에서 구현되어야 한다.\n- System.loadLibary(String libname) - 공유 라이브러리를 파일 시스템에서 메모리로 로드하고 내보낸 함수를 Java 코드에서 사요할 수 있도록 하는 정적 method\n\n### C/C++ Code\n\n- JNIEXPORT - 함수를 공유 라이브러리에 내보내기 기능으로 표시하여 함수 테이블에 포함되므로 JNI가 찾을 수 있다.\n- JNICALL - JNIEXPORT와 결합 하여 JNI 프레임워크에서 method를 사용할 수 있도록 한다.\n- JNIEnv - Native Code를 사용하여 Java 요소에 액세스 할 수 있는 method가 포함된 구조\n- JavaVM - 실행 중인 JVM을 조작할 수 있는 구조에 Thread를 run/interrupt\n\n이제 코드로 작성해보자\n\n## “Hello World” 출력해보기\n\n### 1. Java Code\n\n```java\npublic class HelloJNI {\n    static {\n        System.loadLibrary(\"JNI_Hello\"); // 네이티브 라이브러리를 로드\n    }\n    \n    public native void printHello(); // 네이티브 메서드 선언\n    \n    public static void main(String[] args) {\n        new HelloJNI().sayHello(); // 네이티브 메서드 호출\n    }\n}\n```\n\nmethod를 선언할 때 `native`  keyword 사용\n\n`printHello`가 호출될 때 자바가 아닌 native로 구현된 method를 찾게 된다.\n\nstatic block은 class가 사용될 때, `JNI_Hello` 이름을 가진 라이브러리를 메모리에 Load한다.\n\n### 2. Java Compiler를 사용하여 Class를 Compile한 후, `javah`를 사용하여 헤더 파일을 생성한다.\n\n```bash\njavac HelloJNI.java\njavah -jni HelloJNI\n```\n\njavah를 사용하여 만들어진 header 파일을 살펴보면 아래 코드와 같다.\n\n```c\n/* DO NOT EDIT THIS FILE - it is machine generated */\n#include <jni.h>\n/* Header for class simple_Hello */\n\n#ifndef _Included_simple_Hello\n#define _Included_simple_Hello\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n/*\n * Class:     simple_Hello\n * Method:    printHello\n * Signature: ()V\n */\n\nJNIEXPORT void JNICALL Java_simple_Hello_printHello(JNIEnv *, jobject);\n\n#ifdef __cplusplus\n}\n#endif\n#endif\n```\n\nC파일에 `JNIEXPORT void JNICALL Java_simple_Hello_printHello(JNIEnv *, jobject);`\nMethod를 구현하면 된다. Method이름은 패키지-클래스-메소드 이름으로 되어있다. 따라서 패키지를 java에서 수정하면 native method를 사용하지 못한다.\n\n### 3. C method\n\n```c\n#include <jni.h>\n#include <stdio.h>\n#include \"HelloJNI.h\"\n\nJNIEXPORT void JNICALL Java_simple_Hello_printHello(JNIEnv *env, jobject obj) {\n    printf(\"Hello from C!\\n\");\n}\n```\n\n생성된 헤더 파일을 포함하여 C/C++ 파일을 작성하고 네이티브 메서드를 구현합니다.\n\n### 4. Native Method Compile\n\n작성한 네이티브 코드를 컴파일하여 공유 라이브러리를 생성합니다.\n\n```bash\ngcc -shared -o libhello.so -fPIC HelloJNI.c -I${JAVA_HOME}/include -I${JAVA_HOME}/include/linux\n```\n\n### 5. Java Application 실행\n\n```bash\njava -Djava.library.path=. HelloJNI\n```\n\n## Native Library를 Jar파일에 포함하여 Native Method를 사용해보기\n\n위 예제는 서버 배포과정이 아닌 하나의 Java Application을 실행하는데 옵션을 추가하는 건 별 일 아닐 수 있다. 하지만 JNI를 사용하기 위해 서버 배포시 옵션을 추가해주는 일은 번거로운 일이다.\n\n이를 해결하기 위해선 두 가지 문제점을 해결해야 한다.\n\n1. 옵션을 사용하지 않고 Native Library 사용하기\n2. 하나의 Jar 파일만 사용하기\n\n해결 방법은 resources 폴더 내에 Native Library 포함하여 Jar File을 만든 후 Native static block에서 Native Library를 메모리에 Load 하기 전, resource 폴더에서 Native Library 파일을 copy하여 해당 파일을 Native Library를 메모리에 Load 한다. 코드는 아래와 같다.\n\n[How to bundle a native library and a JNI library inside a JAR?](https://stackoverflow.com/questions/2937406/how-to-bundle-a-native-library-and-a-jni-library-inside-a-jar?rq=1)\n\n```java\nString libName = \"libhello.so \"; // The name of the file in resources/ dir\nURL url = MyClass.class.getResource(\"/\" + libName);\nFile tmpDir = Files.createTempDirectory(\"my-native-lib\").toFile();\ntmpDir.deleteOnExit();\nFile nativeLibTmpFile = new File(tmpDir, libName);\nnativeLibTmpFile.deleteOnExit();\ntry (InputStream in = url.openStream()) {\n    Files.copy(in, nativeLibTmpFile.toPath());\n}\nSystem.load(nativeLibTmpFile.getAbsolutePath());\n```\n\n위 코드와 같이 File에 임시로 Native Library를 copy 한 후 load 하는 방식으로 두 가지 문제점을 해결할 수 있었다.\n\n생성된 File은 JVM이 종료되면 삭제된다.\n"},{"excerpt":"DB Process & Thread Oracle Process Process는 OS에 따라 달라진다 오라클 프로세스는 오라클 데이터베이스 코드를 실행하는 실행 단위입니다.\nProcess Architecture (oracle.com) Multiprocess and MultiThread 데이터베이스와 애플리케이션의 작업을 여러 프로세스로 나누면 여러 사용자와…","fields":{"slug":"/OracleProcess/"},"frontmatter":{"date":"July 14, 2024","title":"Oracle Process","tags":["Database","Oracle"]},"rawMarkdownBody":"\n## DB Process & Thread\n\n### Oracle Process\n\n- Process는 OS에 따라 달라진다\n- 오라클 프로세스는 오라클 데이터베이스 코드를 실행하는 실행 단위입니다.\n[Process Architecture (oracle.com)](https://docs.oracle.com/en/database/oracle/oracle-database/21/cncpt/process-architecture.html#GUID-251AC080-BD5C-415E-8549-B67F8653AD40)\n\n#### Multiprocess and MultiThread\n\n데이터베이스와 애플리케이션의 작업을 여러 프로세스로 나누면 여러 사용자와 애플리케이션이 동시에 인스턴스에 연결할 수 있으며 시스템 성능도 향상됩니다.\n\n쓰레드 모드로 사용하면 일부 프로세스들을 OS 프로세스로 실행 가능하다.\n\nOracle Process ≠ OS Process\n\n### 종류\n\n- Client Process : Application 또는 Oracle Tool 을 실행시킨다.\n    - SQLPlus을 실행시킬 시 OS는 Client Process를 실행시킨다.\n- Background Process : 각 Client Process에 대해 실행 중인 여러 Oracle 프로그램에서 처리할 수 있는 기능을 통합하는 프로세스, 백그라운드 프로세스는 비동기적으로 I/O를 수행하고, 다른 Oracle 프로세스를 모니터링한다.\n- Server Process : 사용자 요청 또는 Client Process 요청을 처리한다.\n\n![OracleStructure](OracleStructure.png)\n\n### Client Process\n\n- ProC Program, SQL Plus 실행 시, OS는 Client Process를 생성한다.\n데이터베이스와 통신하는 데 필요한 API를 제공하는 Oracle 데이터베이스 라이브러리가 연결되어 있습니다.\n- 다른 프로세스들은 SGA를 직접 read, write 할 수 있지만, Client Process는 하지 못한다.\n클라이언트 프로세스는 데이터베이스 호스트가 아닌 다른 호스트에서 실행할 수 있지만 Oracle 프로세스는 그렇지 않습니다.\n\n### Connections and Sessions\n\n- Connection은 Client Process와 데이터베이스 인스턴스 간의 물리적 통신 경로\n- 연결 중에는, IPC 또는 Network Software를 사용할 수 있다.\n- Session은 사용자가 데이터베이스에 의해 인증된 시점부터 사용자가 데이터베이스 애플리케이션 연결을 끊거나 종료할 때까지 지속됩니다.\n\n### Server Process\n\n- 인스턴스에 연결된 클라이언트 프로세스의 요청을 처리하기 위해 서버 프로세스를 생성\n- Client Process는 Server Process를 통해 데이터베이스와 통신한다.\n- Task\n    - 쿼리 계획 생성 및 실행을 포함하여 애플리케이션을 통해 발행된 SQL 문을 구문 분석하고 실행합니다.\n    - PL/SQL 코드 실행\n    - 데이터 파일에서 데이터베이스 버퍼 캐시로 데이터 블록 읽기\n    - Application이 정보를 처리할 수 있는 방식으로 결과를 반환\n\n#### Shared Server Processes\n\n- 여러 Client Process가 하나의 Dispatcher Process에 연결할 수 있다.\n- 연결된 Client의 요청을 수신하여 Pool의 대기열에 넣는다. 사용 가능한 Shared Server가 큐에서 요청을 가져와 처리한다. 그 후 응답 대기열에 결과를 넣는다. Shared Server Process는 큐를 모니터링하고 결과를 클라이언트에게 전송\n\n### Background Process\n\n- 백그라운드 프로세스는 데이터베이스 운영 및 여러 사용자의 성능을 극대화하는 데 필요한 유지 관리 작업을 수행합니다.\n- 각 백그라운드 프로세스에는 별도의 작업이 있지만 다른 프로세스와 함께 작동합니다.\n- 인스턴스 실행 시, 백그라운드 프로세스를 생성한다.\n\n### 필수 Background Process\n\n#### **PMON**\n\n- Process 모니터링 및 Clean up, Buffer Cache , Client Process가 사용하는 자원 관리한다\n- 종료된 프로세스가 보유한 리소스를 다른 프로세스에서 획득할 수 있어야한다.\n    \n    #### **Process Monitor Process (PMON)**\n    \n    - 다른 백그라운드 프로세스의 종료를 감지\n    \n    #### **Cleanup Main Process (CLMN)**\n    \n    - 종료된 프로세스, 종료된 세션, 트랜잭션 등을 정리\n    \n    #### **Cleanup Helper Processes (CLnn)**\n    \n    - 정리 작업 위임받아 실행한다.\n\n#### **Process Manager (PMAN)**\n\n- Shared Server, Pooled Server, Job Queue Process등을 관리한다.\n\n#### **System Monitor Process (SMON)**\n\n- 필요한 경우 인스턴스 시작 시 인스턴스 복구를 수행합니다.\n- 파일 읽기 또는 테이블 스페이스 오프라인 오류로 인해 인스턴스 복구 중에 건너뛴 종료된 트랜잭션을 복구\n- 사용하지 않는 임시 세그먼트를 정리합니다.\n\n#### **Database Writer Process (DBW)**\n\n- 데이터베이스 버퍼의 내용을 데이터 파일에 쓴다.\n- 버퍼 캐시에 있는 수정된 버퍼를 디스크에 쓴다.\n- 대부분 하나의 DBW를 사용하지만, 쓰기 성능을 향상하기 위해 추가 프로세스를 구성할 수 있다.\n단, 단일 프로세스 시스템에선 유효하지 않다.\n- Dirty Buffer를 Disk에 적는 조건\n    - 서버 프로세스가 버퍼를 스캔하는데, 깨끗한 버퍼를 찾지 못한 경우 DBW에 쓰기 신호를 보낸다.\n\n#### **Log Writer Process (LGWR)**\n\n- Online Redo Buffer를 관리한다.\n    - Buffer의 일부분을 Online Redo Log로 write\n- 데이터베이스 버퍼 수정, 디스크 분산 write등 작업을 분리하여 성능 향상\n- 모든 Redo entry들을 버퍼에 write 하는 경우\n    - commit, transaction\n    - log switch 발생 시\n    - Redo log Buffer가 3분의 1이 찼을경우\n\n#### **Checkpoint Process (CKPT)**\n\n- control file, data file header를 체크포인트 정보로 업데이트하고, DBW에 디스크에 write\n- 복구를 시작할 수 있는 Checkpoint 위치, online redo log 위치 포함"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}